model_config:
  hf_id: "QuantFactory/Meta-Llama-3-8B-Instruct-GGUF"
  hf_file: "Meta-Llama-3-8B-Instruct.Q4_K_M.gguf"
  n_threads: 2
  n_batch: 512
  n_gpu_layers: -1
  n_ctx: 8196
  system_prompt: true
  system_prompt_start_token: "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n"
  system_prompt_end_token: "<|eot_id|>"
  user_prompt_start_token: "<|start_header_id|>user<|end_header_id|>\n"
  user_prompt_end_token: "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
  user_followup_prompt_start_token: "<|start_header_id|>user<|end_header_id|>\n"
  user_followup_prompt_end_token: "<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n"
  assistant_prompt_start_token: ""
  assistant_prompt_end_token: "<|eot_id|>"
  assistant_followup_prompt_start_token: ""
  assistant_followup_prompt_end_token: "<|eot_id|>"
  end_tokens:
  - "<|eot_id|>"
  verbose: true
  default_completion_config:
    max_tokens: 8196
    temperature: 0.0
    repeat_penalty: 1.1
    echo: false
    top_p: 1
